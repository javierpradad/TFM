{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c77df65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import ast\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad027618",
   "metadata": {},
   "source": [
    "#### GENERAR DATASET DE SOLO UNA CLASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "755ae538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURACIÓN\n",
    "BASE_IMAGE_DIR = \"E:/TFM/PADCHEST\"  # <-- tu carpeta con subcarpetas 0, 1, ..., 50\n",
    "OUTPUT_DIR = \"E:/TFM/Dataset_una_clase\"  # <-- carpeta donde guardarás el nuevo dataset\n",
    "CSV_PATH = \"E:/TFM/PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv\"\n",
    "\n",
    "# Escoger un hallazgo concreto\n",
    "target_label = \"descendent aortic elongation\"\n",
    "\n",
    "# Cargar CSV y filtrar solo anotaciones manuales\n",
    "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
    "df = df[df[\"MethodLabel\"] == \"Physician\"].copy()\n",
    "\n",
    "# Convertir la columna 'Labels' en listas reales\n",
    "df[\"Labels\"] = df[\"Labels\"].apply(ast.literal_eval)\n",
    "\n",
    "# Etiqueta binaria: positivo si tiene el hallazgo, negativo si no\n",
    "df[\"binary_label\"] = df[\"Labels\"].apply(lambda labels: \"positive\" if target_label in labels else \"negative\")\n",
    "\n",
    "# Nos quedamos con todas las imágenes que tengan el hallazgo + un número similar sin el hallazgo\n",
    "df_pos = df[df[\"binary_label\"] == \"positive\"]\n",
    "df_neg = df[df[\"binary_label\"] == \"negative\"]\n",
    "\n",
    "# Igualar número de negativos al de positivos\n",
    "df_neg_sampled = df_neg.sample(n=len(df_pos), random_state=42)\n",
    "\n",
    "df_binary = pd.concat([df_pos, df_neg_sampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6dc004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset few-shot binario para 'descendent aortic elongation' preparado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Split estratificado\n",
    "train, temp = train_test_split(df_binary, test_size=0.4, stratify=df_binary[\"binary_label\"], random_state=42)\n",
    "val, test = train_test_split(temp, test_size=0.5, stratify=temp[\"binary_label\"], random_state=42)\n",
    "\n",
    "# Añadir columna de split\n",
    "train[\"split\"] = \"train\"\n",
    "val[\"split\"] = \"val\"\n",
    "test[\"split\"] = \"test\"\n",
    "\n",
    "# Unir splits\n",
    "final_df = pd.concat([train, val, test])\n",
    "\n",
    "# Ruta completa a la imagen\n",
    "def build_path(row):\n",
    "    folder = str(row[\"ImageDir\"])\n",
    "    filename = row[\"ImageID\"]\n",
    "    return os.path.join(BASE_IMAGE_DIR, folder, filename)\n",
    "\n",
    "final_df[\"image_path\"] = final_df.apply(build_path, axis=1)\n",
    "\n",
    "# Crear carpetas destino\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for label in [\"positive\", \"negative\"]:\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR, split, label), exist_ok=True)\n",
    "\n",
    "# Copiar archivos\n",
    "copied = []\n",
    "for _, row in final_df.iterrows():\n",
    "    src = row[\"image_path\"]\n",
    "    label = row[\"binary_label\"]\n",
    "    split = row[\"split\"]\n",
    "    dst = os.path.join(OUTPUT_DIR, split, label, os.path.basename(src))\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy2(src, dst)\n",
    "        copied.append((src, dst, label, split, row[\"ImageID\"], row[\"ImageDir\"]))\n",
    "\n",
    "# Guardar resumen en CSV\n",
    "summary_df = pd.DataFrame(copied, columns=[\"source_path\", \"dest_path\", \"label\", \"split\", \"ImageID\", \"ImageDir\"])\n",
    "summary_df.to_csv(os.path.join(OUTPUT_DIR, f\"fewshot_summary_{target_label}.csv\"), index=False)\n",
    "\n",
    "# Generar CSV tipo original pero solo con imágenes copiadas\n",
    "df_images_original = pd.read_csv(CSV_PATH, low_memory=False)\n",
    "ids_copiados = set(summary_df[\"ImageID\"].unique())\n",
    "df_images_fewshot = df_images_original[df_images_original[\"ImageID\"].isin(ids_copiados)].copy()\n",
    "\n",
    "images_fewshot_path = os.path.join(OUTPUT_DIR, f\"PADCHEST_chest_x_ray_images_fewshot_{target_label}.csv\")\n",
    "df_images_fewshot.to_csv(images_fewshot_path, index=False)\n",
    "\n",
    "print(f\"✅ Dataset few-shot binario para '{target_label}' preparado con éxito.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a43d188",
   "metadata": {},
   "source": [
    "#### GENERAR DATASET MULTICLASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f04fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURACIÓN\n",
    "BASE_IMAGE_DIR = \"E:/TFM/PADCHEST\"  # <-- tu carpeta con subcarpetas 0, 1, ..., 50\n",
    "OUTPUT_DIR = \"E:/TFM/Dataset_multiclase\"  # <-- carpeta donde guardarás el nuevo dataset\n",
    "CSV_PATH = \"E:/TFM/PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv\"\n",
    "\n",
    "# Cargar CSV y filtrar solo anotaciones manuales\n",
    "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
    "df = df[df[\"MethodLabel\"] == \"Physician\"].copy()\n",
    "\n",
    "# Convertir la columna 'Labels' en listas reales\n",
    "df[\"Labels\"] = df[\"Labels\"].apply(ast.literal_eval)\n",
    "\n",
    "# Contar frecuencia de todas las etiquetas\n",
    "all_labels = list(chain.from_iterable(df[\"Labels\"]))\n",
    "label_counts = Counter(all_labels)\n",
    "\n",
    "# Seleccionar 15 etiquetas raras con al menos 20 imágenes\n",
    "rare_labels = [label for label, count in sorted(label_counts.items(), key=lambda x: x[1]) if count >= 20][:15]\n",
    "\n",
    "# Filtrar imágenes que contienen al menos una etiqueta rara\n",
    "df[\"matched_rare_labels\"] = df[\"Labels\"].apply(lambda x: list(set(x) & set(rare_labels)))\n",
    "df = df[df[\"matched_rare_labels\"].map(len) > 0].copy()\n",
    "\n",
    "# Expandir dataframe por etiqueta\n",
    "df_exploded = df.explode(\"matched_rare_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190808ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset few-shot preparado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Split estratificado\n",
    "train, temp = train_test_split(df_exploded, test_size=0.4, stratify=df_exploded[\"matched_rare_labels\"], random_state=42)\n",
    "val, test = train_test_split(temp, test_size=0.5, stratify=temp[\"matched_rare_labels\"], random_state=42)\n",
    "\n",
    "# Añadir columna de split\n",
    "train[\"split\"] = \"train\"\n",
    "val[\"split\"] = \"val\"\n",
    "test[\"split\"] = \"test\"\n",
    "\n",
    "# Unir splits\n",
    "final_df = pd.concat([train, val, test])\n",
    "\n",
    "# Ruta completa a la imagen\n",
    "def build_path(row):\n",
    "    folder = str(row[\"ImageDir\"])\n",
    "    filename = row[\"ImageID\"]\n",
    "    return os.path.join(BASE_IMAGE_DIR, folder, filename)\n",
    "\n",
    "final_df[\"image_path\"] = final_df.apply(build_path, axis=1)\n",
    "final_df[\"label\"] = final_df[\"matched_rare_labels\"]\n",
    "\n",
    "# Crear carpetas destino\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for label in rare_labels:\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR, split, label), exist_ok=True)\n",
    "\n",
    "# Copiar archivos\n",
    "copied = []\n",
    "for _, row in final_df.iterrows():\n",
    "    src = row[\"image_path\"]\n",
    "    label = row[\"label\"]\n",
    "    split = row[\"split\"]\n",
    "    dst = os.path.join(OUTPUT_DIR, split, label, os.path.basename(src))\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy2(src, dst)\n",
    "        copied.append((src, dst, label, split, row[\"ImageID\"], row[\"ImageDir\"]))\n",
    "\n",
    "# Guardar resumen en CSV (ahora incluye ImageID y ImageDir)\n",
    "summary_df = pd.DataFrame(copied, columns=[\"source_path\", \"dest_path\", \"label\", \"split\", \"ImageID\", \"ImageDir\"])\n",
    "summary_df.to_csv(os.path.join(OUTPUT_DIR, \"fewshot_summary.csv\"), index=False)\n",
    "\n",
    "# Generar CSV tipo \"PADCHEST_chest_x_ray_images_160k_01.02.19.csv\" pero solo con imágenes copiadas\n",
    "original_images_csv = \"E:/TFM/PADCHEST_chest_x_ray_images_labels_160k_01.02.19.csv\"  # Ruta del original\n",
    "df_images_original = pd.read_csv(original_images_csv, low_memory=False)\n",
    "\n",
    "# Filtrar por las imágenes copiadas\n",
    "ids_copiados = set(summary_df[\"ImageID\"].unique())\n",
    "df_images_fewshot = df_images_original[df_images_original[\"ImageID\"].isin(ids_copiados)].copy()\n",
    "\n",
    "# Guardar CSV filtrado\n",
    "images_fewshot_path = os.path.join(OUTPUT_DIR, \"PADCHEST_chest_x_ray_images_fewshot.csv\")\n",
    "df_images_fewshot.to_csv(images_fewshot_path, index=False)\n",
    "\n",
    "print(\"✅ Dataset few-shot preparado con éxito.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
